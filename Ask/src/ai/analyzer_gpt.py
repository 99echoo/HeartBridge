"""
íŒŒì¼ëª…: analyzer_gpt.py
ëª©ì : GPT-4o ê¸°ë°˜ 2ë‹¨ê³„ AI ë¶„ì„ (JSON Schema + Self-Healing)
ì‘ì„±ì¼: 2025-01-26
ìˆ˜ì •ì¼: 2025-01-26 - JSON Schema ê°•ì œ, Self-Healing ë¡œì§, asyncio ê°œì„ 
"""

import json
import re
import asyncio
import logging
from pathlib import Path
from typing import Dict, Optional, List, Any
from openai import OpenAI, APIError

from config.settings import settings
from src.ai.prompt_builder_gpt import (
    build_expert_analysis_prompt,
    build_mari_conversion_prompt,
)
from src.ai.gpt4_vision import (
    analyze_dog_image_with_gpt4,
    get_fallback_vision_analysis,
)
from src.ai.schemas import (
    EXPERT_ANALYSIS_SCHEMA,
    normalize_expert_json,
    validate_expert_json,
)
from src.utils.mock_data import get_mock_result_by_problem


# ===== ë¡œê¹… ì„¤ì • =====

def setup_logger():
    """analyzer_gpt.py ì „ìš© ë¡œê±°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    logger = logging.getLogger("analyzer_gpt")
    logger.setLevel(logging.DEBUG)

    if logger.handlers:
        logger.handlers.clear()

    log_dir = Path(__file__).parent.parent.parent / "logs"
    log_dir.mkdir(exist_ok=True)
    log_file = log_dir / "analyzer_gpt.log"

    file_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)

    formatter = logging.Formatter(
        '[%(asctime)s] [%(levelname)s] %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

    return logger


logger = setup_logger()


# ===== GPT-4o API í˜¸ì¶œ (JSON Schema ê°•ì œ) =====

async def call_gpt4_api(
    system: str,
    user: str,
    max_retries: int = 3,
    model: str = "gpt-4o",
    use_json_schema: bool = False,
    json_schema: Optional[Dict[str, Any]] = None,
    temperature: float = 0.7
) -> str:
    """
    GPT-4o APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤ (JSON Schema ê°•ì œ ì§€ì›, ë¹„ë™ê¸° ì¬ì‹œë„).

    Args:
        system: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        user: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
        max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        model: GPT ëª¨ë¸ëª…
        use_json_schema: JSON Schema ê°•ì œ ì‚¬ìš© ì—¬ë¶€
        json_schema: JSON Schema ê°ì²´
        temperature: ì˜¨ë„ (ì°½ì˜ì„±)

    Returns:
        str: AI ì‘ë‹µ í…ìŠ¤íŠ¸

    Raises:
        Exception: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
    """
    client = OpenAI(api_key=settings.OPENAI_API_KEY)
    logger.info(f"GPT-4o API í˜¸ì¶œ ì‹œì‘ (model={model}, json_schema={use_json_schema}, temp={temperature})")
    logger.debug(f"System prompt ê¸¸ì´: {len(system)} chars")
    logger.debug(f"User prompt ê¸¸ì´: {len(user)} chars")

    for attempt in range(max_retries + 1):
        try:
            logger.debug(f"API í˜¸ì¶œ ì‹œë„ {attempt + 1}/{max_retries + 1}")

            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                {"role": "system", "content": system},
                {"role": "user", "content": user}
            ]

            # API í˜¸ì¶œ
            if use_json_schema and json_schema:
                # JSON Schema ê°•ì œ ëª¨ë“œ
                response = client.chat.completions.create(
                    model=model,
                    messages=messages,
                    max_tokens=4096,
                    temperature=temperature,
                    response_format={
                        "type": "json_schema",
                        "json_schema": json_schema
                    }
                )
            else:
                # ì¼ë°˜ ëª¨ë“œ
                response = client.chat.completions.create(
                    model=model,
                    messages=messages,
                    max_tokens=4096,
                    temperature=temperature
                )

            response_text = response.choices[0].message.content
            logger.info(f"GPT-4o API í˜¸ì¶œ ì„±ê³µ (ì‘ë‹µ ê¸¸ì´: {len(response_text)} chars)")

            # ì‚¬ìš©ëŸ‰ ë¡œê¹…
            if hasattr(response, 'usage'):
                logger.info(f"í† í° ì‚¬ìš©ëŸ‰: prompt={response.usage.prompt_tokens}, completion={response.usage.completion_tokens}, total={response.usage.total_tokens}")

            return response_text

        except APIError as e:
            logger.error(f"OpenAI API ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries + 1}): {str(e)}")
            if attempt < max_retries:
                wait_time = (2 ** attempt) * 0.5  # ì§€ìˆ˜ ë°±ì˜¤í”„: 0.5s, 1s, 2s
                logger.warning(f"{wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                await asyncio.sleep(wait_time)  # ë¹„ë™ê¸° sleep
                continue
            else:
                error_msg = f"GPT-4o API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {max_retries + 1}íšŒ): {str(e)}"
                logger.critical(error_msg)
                raise Exception(error_msg)

        except Exception as e:
            logger.error(f"ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries + 1}): {str(e)}")
            if attempt < max_retries:
                wait_time = (2 ** attempt) * 0.5
                logger.warning(f"{wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                await asyncio.sleep(wait_time)
                continue
            else:
                error_msg = f"ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {str(e)}"
                logger.critical(error_msg)
                raise Exception(error_msg)


# ===== JSON íŒŒì‹± ë° ê²€ì¦ =====

def parse_json_response(response: str) -> dict:
    """
    AI ì‘ë‹µì—ì„œ JSONì„ íŒŒì‹±í•©ë‹ˆë‹¤.

    Args:
        response: AI ì‘ë‹µ í…ìŠ¤íŠ¸

    Returns:
        dict: íŒŒì‹±ëœ JSON

    Raises:
        ValueError: JSON íŒŒì‹± ì‹¤íŒ¨
    """
    # JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„
    json_match = re.search(r"```json\s*\n(.*?)\n```", response, re.DOTALL)
    if json_match:
        json_str = json_match.group(1)
    else:
        json_str = response

    try:
        result = json.loads(json_str)
        return result
    except json.JSONDecodeError as e:
        raise ValueError(f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")


# ===== Self-Healing: ìˆ˜ì • í”„ë¡¬í”„íŠ¸ =====

async def fix_json_with_prompt(
    broken_json: dict,
    error_message: str,
    original_prompt: str
) -> dict:
    """
    JSONì´ ìŠ¤í‚¤ë§ˆë¥¼ ìœ„ë°˜í•œ ê²½ìš°, GPTì—ê²Œ ìˆ˜ì •ì„ ìš”ì²­í•©ë‹ˆë‹¤.

    Args:
        broken_json: ë¬¸ì œê°€ ìˆëŠ” JSON
        error_message: ê²€ì¦ ì‹¤íŒ¨ ë©”ì‹œì§€
        original_prompt: ì›ë˜ í”„ë¡¬í”„íŠ¸ (ì»¨í…ìŠ¤íŠ¸)

    Returns:
        dict: ìˆ˜ì •ëœ JSON

    Raises:
        Exception: ìˆ˜ì • ì‹¤íŒ¨ ì‹œ
    """
    logger.info("=== Self-Healing: JSON ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ì‹œë„ ===")

    fix_prompt = f"""ì•„ë˜ JSONì´ ê·œì¹™ì„ ìœ„ë°˜í–ˆìŠµë‹ˆë‹¤. ì •í™•íˆ ìˆ˜ì •í•´ì£¼ì„¸ìš”.

**ì›ë˜ ìš”êµ¬ì‚¬í•­:**
{original_prompt[:500]}...

**ë¬¸ì œê°€ ìˆëŠ” JSON:**
```json
{json.dumps(broken_json, ensure_ascii=False, indent=2)}
```

**ê²€ì¦ ì‹¤íŒ¨ ì‚¬ìœ :**
{error_message}

**ìˆ˜ì • ìš”êµ¬ì‚¬í•­:**
1. solutions_best_fitëŠ” ì •í™•íˆ 3ê°œì—¬ì•¼ í•©ë‹ˆë‹¤.
2. future_guidanceëŠ” ì •í™•íˆ 3ê°œì—¬ì•¼ í•©ë‹ˆë‹¤.
3. ëª¨ë“  í•„ìˆ˜ í•„ë“œë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
4. JSONë§Œ ì¶œë ¥í•˜ì„¸ìš” (ì„¤ëª… ë¶ˆí•„ìš”).
"""

    try:
        fixed_response = await call_gpt4_api(
            system="ë„ˆëŠ” JSON ê²€ì¦ ì „ë¬¸ê°€ë‹¤. ê·œì¹™ì„ ì •í™•íˆ ë”°ë¥¸ JSONë§Œ ì¶œë ¥í•œë‹¤.",
            user=fix_prompt,
            max_retries=1,
            use_json_schema=True,
            json_schema=EXPERT_ANALYSIS_SCHEMA,
            temperature=0.3  # ë‚®ì€ ì˜¨ë„ë¡œ ì •í™•ì„± í™•ë³´
        )

        fixed_json = parse_json_response(fixed_response)
        logger.info("JSON ìˆ˜ì • ì„±ê³µ!")
        return fixed_json

    except Exception as e:
        logger.error(f"JSON ìˆ˜ì • ì‹¤íŒ¨: {str(e)}")
        raise


# ===== 2ë‹¨ê³„ AI ë¶„ì„ ë©”ì¸ í•¨ìˆ˜ =====

async def analyze_two_stage(
    responses: dict,
    dog_photo: bytes,
    behavior_media: Optional[bytes] = None
) -> dict:
    """
    2ë‹¨ê³„ AI ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤ (GPT-4o, JSON Schema, Self-Healing).

    Args:
        responses: st.session_state.responses (ì„¤ë¬¸ ì‘ë‹µ)
        dog_photo: ê°•ì•„ì§€ ì‚¬ì§„ ë°”ì´íŠ¸
        behavior_media: í–‰ë™ ì˜ìƒ/ì‚¬ì§„ ë°”ì´íŠ¸ (Optional)

    Returns:
        dict: {
            "final_text": str,
            "confidence_score": float,
            "raw_json": dict
        }
    """
    dog_name = responses.get("dog_name", "ê°•ì•„ì§€")
    dog_age = responses.get("dog_birth", "ì•Œ ìˆ˜ ì—†ìŒ")
    hardest_part = responses.get("hardest_part", "ì•Œ ìˆ˜ ì—†ìŒ")
    main_concerns = responses.get("main_concerns", [])

    # ===== 0ë‹¨ê³„: GPT-4 Vision ì´ë¯¸ì§€ ì „ì²˜ë¦¬ =====
    logger.info(f"=== GPT-4 Vision ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹œì‘ (ê°•ì•„ì§€: {dog_name}) ===")

    vision_analysis = None
    try:
        vision_analysis = await analyze_dog_image_with_gpt4(
            image_bytes=dog_photo,
            max_retries=2
        )
        logger.info("GPT-4 Vision ì´ë¯¸ì§€ ë¶„ì„ ì„±ê³µ!")

    except Exception as e:
        logger.error(f"GPT-4 Vision ì‹¤íŒ¨, Fallback ì‚¬ìš©: {str(e)}")
        vision_analysis = get_fallback_vision_analysis(dog_name=dog_name)

    # ===== 1ì°¨ AI: ì „ë¬¸ê°€ ë¶„ì„ (JSON Schema ê°•ì œ) =====
    logger.info(f"=== 1ì°¨ AI ë¶„ì„ ì‹œì‘ (GPT-4o + JSON Schema, ê°•ì•„ì§€: {dog_name}) ===")

    raw_json = None
    try:
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        logger.debug("1ì°¨ AI í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
        expert_prompt = build_expert_analysis_prompt(
            responses=responses,
            dog_photo=dog_photo,
            behavior_media=behavior_media,
            vision_analysis=vision_analysis
        )

        # GPT-4o API í˜¸ì¶œ (JSON Schema ê°•ì œ)
        logger.info("1ì°¨ AI GPT-4o API í˜¸ì¶œ ì‹œì‘ (JSON Schema ê°•ì œ)...")
        raw_response = await call_gpt4_api(
            system=expert_prompt["system"],
            user=expert_prompt["user"],
            max_retries=3,
            model="gpt-4o",
            use_json_schema=True,
            json_schema=EXPERT_ANALYSIS_SCHEMA,
            temperature=0.4  # ë‚®ì€ ì˜¨ë„ë¡œ ì •í™•ì„± í™•ë³´
        )

        # JSON íŒŒì‹±
        logger.debug("1ì°¨ AI ì‘ë‹µ JSON íŒŒì‹± ì¤‘...")
        raw_json = parse_json_response(raw_response)

        # ===== Self-Healing: Schema ê²€ì¦ =====
        is_valid, error_msg = validate_expert_json(raw_json)

        if not is_valid:
            logger.warning(f"Schema ê²€ì¦ ì‹¤íŒ¨: {error_msg}")
            logger.info("=== Self-Healing ë‹¨ê³„ 1: Normalize ì‹œë„ ===")

            # 1) Normalize (ìë™ ë³´ì •)
            raw_json = normalize_expert_json(raw_json)
            logger.info("Normalize ì™„ë£Œ")

            # 2) ì¬ê²€ì¦
            is_valid, error_msg = validate_expert_json(raw_json)

            if not is_valid:
                logger.warning(f"Normalize í›„ì—ë„ ê²€ì¦ ì‹¤íŒ¨: {error_msg}")
                logger.info("=== Self-Healing ë‹¨ê³„ 2: ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ì‹œë„ ===")

                # 3) ìˆ˜ì • í”„ë¡¬í”„íŠ¸
                try:
                    raw_json = await fix_json_with_prompt(
                        broken_json=raw_json,
                        error_message=error_msg,
                        original_prompt=expert_prompt["user"]
                    )

                    # 4) ìµœì¢… ê²€ì¦
                    is_valid, error_msg = validate_expert_json(raw_json)

                    if not is_valid:
                        logger.error(f"ìˆ˜ì • í”„ë¡¬í”„íŠ¸ í›„ì—ë„ ê²€ì¦ ì‹¤íŒ¨: {error_msg}")
                        logger.warning("ìµœì¢… Normalize ì ìš©")
                        raw_json = normalize_expert_json(raw_json)

                except Exception as fix_error:
                    logger.error(f"ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ì‹¤íŒ¨: {str(fix_error)}")
                    logger.warning("Normalizeë¡œ ë³µêµ¬")
                    raw_json = normalize_expert_json(raw_json)

        logger.info("1ì°¨ AI ë¶„ì„ ë° ê²€ì¦ ì™„ë£Œ!")

    except Exception as e:
        # ìµœí›„ í´ë°±: Mock ë°ì´í„°
        logger.error(f"===== 1ì°¨ AI ì‹¤íŒ¨ - Mock ë°ì´í„° í´ë°± =====")
        logger.error(f"Error: {str(e)}", exc_info=True)

        problem_type = main_concerns[0] if main_concerns else "barking"
        mock_result = get_mock_result_by_problem(problem_type)

        raw_json = {
            "analysis_summary": {
                "core_issue": "ë¶„ì„ ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸°ë³¸ ì‘ë‹µ",
                "root_cause": "API ì˜¤ë¥˜",
                "key_characteristics": ["ì •ë³´ ë¶€ì¡±", "ì„ì‹œ ì‘ë‹µ", "ì¬ì‹œë„ ê¶Œì¥"]
            },
            "solutions_best_fit": [
                {"title": "ì†”ë£¨ì…˜ 1", "content": "ê¸°ë³¸ ì†”ë£¨ì…˜", "details": ["ì„ì‹œ ì‘ë‹µ"], "expected_outcome": "ê°œì„  ê¸°ëŒ€"},
                {"title": "ì†”ë£¨ì…˜ 2", "content": "ê¸°ë³¸ ì†”ë£¨ì…˜", "details": ["ì„ì‹œ ì‘ë‹µ"], "expected_outcome": "ê°œì„  ê¸°ëŒ€"},
                {"title": "ì†”ë£¨ì…˜ 3", "content": "ê¸°ë³¸ ì†”ë£¨ì…˜", "details": ["ì„ì‹œ ì‘ë‹µ"], "expected_outcome": "ê°œì„  ê¸°ëŒ€"}
            ],
            "future_guidance": [
                {"principle": "ì›ì¹™ 1", "content": "ë‚´ìš©", "action": "í–‰ë™"},
                {"principle": "ì›ì¹™ 2", "content": "ë‚´ìš©", "action": "í–‰ë™"},
                {"principle": "ì›ì¹™ 3", "content": "ë‚´ìš©", "action": "í–‰ë™"}
            ],
            "core_message": "ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "confidence_score": 0.3
        }

    # ===== 2ì°¨ AI: ë§ˆë¦¬ í˜ë¥´ì†Œë‚˜ ë³€í™˜ (ìì—°ì–´) =====
    logger.info(f"=== 2ì°¨ AI ë³€í™˜ ì‹œì‘ (GPT-4o, ê°•ì•„ì§€: {dog_name}) ===")

    try:
        mari_prompt = build_mari_conversion_prompt(
            raw_json=raw_json,
            dog_name=dog_name,
            dog_age=dog_age,
            hardest_part=hardest_part
        )

        # GPT-4o API í˜¸ì¶œ (í…ìŠ¤íŠ¸ ëª¨ë“œ, ë†’ì€ temperature)
        logger.info("2ì°¨ AI GPT-4o API í˜¸ì¶œ ì‹œì‘ (í…ìŠ¤íŠ¸ ëª¨ë“œ)...")
        final_text = await call_gpt4_api(
            system=mari_prompt["system"],
            user=mari_prompt["user"],
            max_retries=2,
            model="gpt-4o",
            use_json_schema=False,
            temperature=0.7  # ìì—°ìŠ¤ëŸ¬ìš´ í†¤ì„ ìœ„í•´ ë†’ì€ ì˜¨ë„
        )
        logger.info("2ì°¨ AI ë³€í™˜ ì„±ê³µ!")

    except Exception as e:
        logger.error(f"===== 2ì°¨ AI ì‹¤íŒ¨ - simple_template_conversion í´ë°± =====")
        logger.error(f"Error: {str(e)}", exc_info=True)
        final_text = simple_template_conversion(raw_json, dog_name, dog_age)

    # ê²°ê³¼ ë°˜í™˜
    return {
        "final_text": final_text,
        "confidence_score": raw_json.get("confidence_score", 0.5),
        "raw_json": raw_json
    }


# ===== í´ë°±: ê°„ë‹¨í•œ í…œí”Œë¦¿ ë³€í™˜ =====

def simple_template_conversion(raw_json: dict, dog_name: str, dog_age: str) -> str:
    """
    2ì°¨ AI ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê°„ë‹¨í•œ í…œí”Œë¦¿ ë³€í™˜.

    Args:
        raw_json: 1ì°¨ AI ê²°ê³¼
        dog_name: ê°•ì•„ì§€ ì´ë¦„
        dog_age: ê°•ì•„ì§€ ë‚˜ì´

    Returns:
        str: Markdown í…ìŠ¤íŠ¸
    """
    summary = raw_json.get("analysis_summary", {})
    solutions = raw_json.get("solutions_best_fit", [])
    guidance = raw_json.get("future_guidance", [])
    core_message = raw_json.get("core_message", "")

    text = f"""**"{dog_name}({dog_age})ì˜ í–‰ë™ ë¶„ì„ ê²°ê³¼ì˜ˆìš”!"**

{summary.get("core_issue", "ë¶„ì„ ê²°ê³¼")}

---

ğŸ¾ **ì´ëŸ° ì†”ë£¨ì…˜ì´ {dog_name}ì—ê²Œ ê°€ì¥ ì˜ ë§ì•„ìš”!**

"""

    # ì†”ë£¨ì…˜ 3ê°œ ì¶”ê°€
    for i, sol in enumerate(solutions[:3], 1):
        text += f"""**{i}. {sol.get("title", f"ì†”ë£¨ì…˜ {i}")}**

{sol.get("content", "ë‚´ìš© ì—†ìŒ")}

"""

    # ì½”ì–´ ë©”ì‹œì§€
    if core_message:
        text += f"""ğŸŒ± **ë§ˆë¦¬ì˜ í•œë§ˆë””:**

"{core_message}"

---

"""

    # ë¯¸ë˜ ê°€ì´ë˜ìŠ¤
    text += f"""ğŸ¾ **ì•ìœ¼ë¡œ ì´ë ‡ê²Œ í•´ë³´ì„¸ìš”!**

"""

    for g in guidance[:3]:
        text += f"- {g.get('principle', 'ì›ì¹™')}: {g.get('action', 'í–‰ë™')}\n"

    text += f"""

**{dog_name}ëŠ” ì˜í•˜ê³  ìˆì–´ìš”. ë³´í˜¸ìë‹˜ë„ ë„ˆë¬´ ì˜í•˜ê³  ê³„ì„¸ìš” ğŸ’›**
"""

    return text
