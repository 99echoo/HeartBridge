"""
íŒŒì¼ëª…: analyzer_gpt5.py
ëª©ì : GPT-5 Responses API ê¸°ë°˜ 2ë‹¨ê³„ AI ë¶„ì„ (JSON Schema + Self-Healing + verbosity + reasoning_effort)
ì‘ì„±ì¼: 2025-01-26
ìˆ˜ì •ì¼: 2025-01-26 - GPT-5 Responses API ì „í™˜, verbosity/reasoning_effort ì ìš©
"""

import json
import re
import asyncio
import logging
import contextlib
from typing import Dict, Optional, Any
from openai import OpenAI, APIError

from config.settings import settings
from src.ai.prompt_builder_gpt import (
    build_expert_analysis_prompt,
    build_mari_conversion_prompt,
)
from src.ai.gpt4_vision import (
    analyze_dog_image_with_gpt4,
    get_fallback_vision_analysis,
)
from src.ai.schemas import (
    EXPERT_ANALYSIS_SCHEMA,
    MARI_NARRATIVE_SCHEMA,
    normalize_expert_json,
    validate_expert_json,
)
from src.utils.mock_data import get_mock_result_by_problem
from src.utils.paths import get_runtime_logs_dir
from src.utils.perf import PerformanceTracker


# ===== ë¡œê¹… ì„¤ì • =====

def setup_logger():
    """analyzer_gpt5.py ì „ìš© ë¡œê±°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    logger = logging.getLogger("analyzer_gpt5")
    logger.setLevel(logging.DEBUG)

    if logger.handlers:
        logger.handlers.clear()

    log_dir = get_runtime_logs_dir()
    log_file = log_dir / "analyzer_gpt5.log"

    file_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)

    formatter = logging.Formatter(
        '[%(asctime)s] [%(levelname)s] %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

    return logger


logger = setup_logger()


# ===== GPT-5 Responses API í˜¸ì¶œ (JSON Schema ê°•ì œ + verbosity + reasoning_effort) =====

async def call_gpt5_api(
    system: str,
    user: str,
    max_retries: int = 3,
    model: str = None,
    use_json_schema: bool = False,
    json_schema: Optional[Dict[str, Any]] = None,
    temperature: float = 0.7,
    verbosity: str = "medium",
    reasoning_effort: str = "medium"
) -> str:
    if model is None:
        model = settings.AI_TEXT_MODEL
    client = OpenAI(api_key=settings.OPENAI_API_KEY)

    reasoning_prefixes = ("gpt-5", "o1", "o3")
    is_reasoning_model = model.startswith(reasoning_prefixes)

    logger.info(
        f"GPT-5 Responses API í˜¸ì¶œ ì‹œì‘ (model={model}, json_schema={use_json_schema}, temp={temperature}, verbosity={verbosity}, reasoning={reasoning_effort})"
    )
    logger.debug(f"System prompt ê¸¸ì´: {len(system)} chars")
    logger.debug(f"User prompt ê¸¸ì´: {len(user)} chars")

    for attempt in range(max_retries + 1):
        try:
            logger.debug(f"API í˜¸ì¶œ ì‹œë„ {attempt + 1}/{max_retries + 1}")

            input_messages = [
                {"role": "system", "content": system},
                {"role": "user", "content": user}
            ]

            base_args: dict[str, Any] = {
                "model": model,
                "input": input_messages,
                "max_output_tokens": 8192,
                "reasoning": {"effort": reasoning_effort},
            }
            if (not is_reasoning_model) and (temperature is not None):
                base_args["temperature"] = temperature

            if use_json_schema and json_schema:
                schema_name = (
                    json_schema.get("name")
                    or json_schema.get("title")
                    or "structured_output"
                )
                schema_body = json_schema.get("schema", json_schema)
                base_args["text"] = {
                    "verbosity": verbosity,
                    "format": {
                        "type": "json_schema",
                        "name": schema_name,
                        "schema": schema_body,
                        "strict": json_schema.get("strict", True),
                    },
                }
                response = client.responses.create(**base_args)
                response_text = response.output_text
            else:
                base_args["text"] = {
                    "verbosity": verbosity,
                }
                response = client.responses.create(**base_args)
                response_text = response.output_text

            logger.info(f"GPT-5 API í˜¸ì¶œ ì„±ê³µ (ì‘ë‹µ ê¸¸ì´: {len(response_text)} chars)")

            if hasattr(response, "usage") and response.usage is not None:
                try:
                    logger.info(
                        "í† í° ì‚¬ìš©ëŸ‰: prompt=%s, completion=%s, total=%s",
                        getattr(response.usage, "prompt_tokens", None),
                        getattr(response.usage, "completion_tokens", None),
                        getattr(response.usage, "total_tokens", None),
                    )
                except Exception:
                    pass

            return response_text

        except APIError as e:
            logger.error(f"OpenAI API ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries + 1}): {str(e)}")
            if attempt < max_retries:
                wait_time = (2 ** attempt) * 0.5
                logger.warning(f"{wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                await asyncio.sleep(wait_time)
                continue
            else:
                error_msg = f"GPT-5 API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {max_retries + 1}íšŒ): {str(e)}"
                logger.critical(error_msg)
                raise Exception(error_msg)

        except Exception as e:
            logger.error(f"ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries + 1}): {str(e)}")
            if attempt < max_retries:
                wait_time = (2 ** attempt) * 0.5
                logger.warning(f"{wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                await asyncio.sleep(wait_time)
                continue
            else:
                error_msg = f"ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {str(e)}"
                logger.critical(error_msg)
                raise Exception(error_msg)


# ===== JSON íŒŒì‹± ë° ê²€ì¦ =====

def parse_json_response(response: str) -> dict:
    """
    AI ì‘ë‹µì—ì„œ JSONì„ íŒŒì‹±í•©ë‹ˆë‹¤.

    Args:
        response: AI ì‘ë‹µ í…ìŠ¤íŠ¸

    Returns:
        dict: íŒŒì‹±ëœ JSON

    Raises:
        ValueError: JSON íŒŒì‹± ì‹¤íŒ¨
    """
    try:
        result = json.loads(response)
        return result
    except json.JSONDecodeError as e:
        raise ValueError(f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")


# ===== Self-Healing: ìˆ˜ì • í”„ë¡¬í”„íŠ¸ =====

async def fix_json_with_prompt(
    broken_json: dict,
    error_message: str,
    original_prompt: str
) -> dict:
    """
    JSONì´ ìŠ¤í‚¤ë§ˆë¥¼ ìœ„ë°˜í•œ ê²½ìš°, GPT-5ì—ê²Œ ìˆ˜ì •ì„ ìš”ì²­í•©ë‹ˆë‹¤.

    Args:
        broken_json: ë¬¸ì œê°€ ìˆëŠ” JSON
        error_message: ê²€ì¦ ì‹¤íŒ¨ ë©”ì‹œì§€
        original_prompt: ì›ë˜ í”„ë¡¬í”„íŠ¸ (ì»¨í…ìŠ¤íŠ¸)

    Returns:
        dict: ìˆ˜ì •ëœ JSON

    Raises:
        Exception: ìˆ˜ì • ì‹¤íŒ¨ ì‹œ
    """
    logger.info("=== Self-Healing: JSON ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ì‹œë„ ===")

    fix_prompt = f"""ì•„ë˜ JSONì´ ê·œì¹™ì„ ìœ„ë°˜í–ˆìŠµë‹ˆë‹¤. ì •í™•íˆ ìˆ˜ì •í•´ì£¼ì„¸ìš”.

**ì›ë˜ ìš”êµ¬ì‚¬í•­:**
{original_prompt[:500]}...

**ë¬¸ì œê°€ ìˆëŠ” JSON:**
```json
{json.dumps(broken_json, ensure_ascii=False, indent=2)}
```

**ê²€ì¦ ì‹¤íŒ¨ ì‚¬ìœ :**
{error_message}

**ìˆ˜ì • ìš”êµ¬ì‚¬í•­:**
1. solutions_best_fitëŠ” ì •í™•íˆ 3ê°œì—¬ì•¼ í•©ë‹ˆë‹¤.
2. future_guidanceëŠ” ì •í™•íˆ 3ê°œì—¬ì•¼ í•©ë‹ˆë‹¤.
3. ëª¨ë“  í•„ìˆ˜ í•„ë“œë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
4. JSONë§Œ ì¶œë ¥í•˜ì„¸ìš” (ì„¤ëª… ë¶ˆí•„ìš”).
"""

    try:
        fixed_response = await call_gpt5_api(
            system="ë„ˆëŠ” JSON ê²€ì¦ ì „ë¬¸ê°€ë‹¤. ê·œì¹™ì„ ì •í™•íˆ ë”°ë¥¸ JSONë§Œ ì¶œë ¥í•œë‹¤.",
            user=fix_prompt,
            max_retries=1,
            use_json_schema=True,
            json_schema=EXPERT_ANALYSIS_SCHEMA,
            temperature=0.3,
            verbosity="low",  # ìˆ˜ì •ì€ ê°„ê²°í•˜ê²Œ
            reasoning_effort="medium"  # ì¤‘ê°„ ì¶”ë¡ 
        )

        fixed_json = parse_json_response(fixed_response)
        logger.info("JSON ìˆ˜ì • ì„±ê³µ!")
        return fixed_json

    except Exception as e:
        logger.error(f"JSON ìˆ˜ì • ì‹¤íŒ¨: {str(e)}")
        raise


# ===== 2ë‹¨ê³„ AI ë¶„ì„ ë©”ì¸ í•¨ìˆ˜ =====

async def analyze_two_stage(
    responses: dict,
    dog_photo: bytes,
    behavior_media: Optional[bytes] = None
) -> dict:
    """
    2ë‹¨ê³„ AI ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤ (GPT-5 Responses API, JSON Schema, Self-Healing).

    Args:
        responses: st.session_state.responses (ì„¤ë¬¸ ì‘ë‹µ)
        dog_photo: ê°•ì•„ì§€ ì‚¬ì§„ ë°”ì´íŠ¸
        behavior_media: í–‰ë™ ì˜ìƒ/ì‚¬ì§„ ë°”ì´íŠ¸ (Optional)

    Returns:
        dict: {
            "final_text": str,
            "confidence_score": float,
            "raw_json": dict
        }
    """
    dog_name = responses.get("dog_name", "ê°•ì•„ì§€")
    dog_age = responses.get("dog_birth", "ì•Œ ìˆ˜ ì—†ìŒ")
    hardest_part = responses.get("hardest_part", "ì•Œ ìˆ˜ ì—†ìŒ")
    main_concerns = responses.get("main_concerns", [])

    tracker = PerformanceTracker(
        name="analyze_two_stage",
        metadata={"dog_name": dog_name, "app_env": settings.APP_ENV, "main_concerns": main_concerns}
    )
    final_status = "success"
    vision_fallback_used = False
    expert_mock_used = False
    mari_template_used = False

    try:
        # ===== 0ë‹¨ê³„: GPT-4o Vision ì´ë¯¸ì§€ ì „ì²˜ë¦¬ =====
        logger.info(f"=== GPT-4o Vision ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹œì‘ (ê°•ì•„ì§€: {dog_name}) ===")

        vision_analysis = None
        vision_task = asyncio.create_task(
            analyze_dog_image_with_gpt4(
                image_bytes=dog_photo,
                max_retries=2
            )
        )
        try:
            with tracker.span("vision_analysis"):
                vision_analysis = await asyncio.wait_for(
                    vision_task,
                    timeout=settings.VISION_TIMEOUT_SECONDS
                )
            logger.info("GPT-4o Vision ì´ë¯¸ì§€ ë¶„ì„ ì„±ê³µ!")

        except asyncio.TimeoutError:
            vision_fallback_used = True
            logger.warning("GPT-4o Vision ë¶„ì„ì´ ì§€ì—°ë˜ì–´ Fallbackìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            vision_task.cancel()
            with contextlib.suppress(Exception):
                await vision_task
            vision_analysis = get_fallback_vision_analysis(dog_name=dog_name)

        except Exception as e:
            vision_fallback_used = True
            logger.error(f"GPT-4o Vision ì‹¤íŒ¨, Fallback ì‚¬ìš©: {str(e)}")
            vision_analysis = get_fallback_vision_analysis(dog_name=dog_name)

        tracker.mark_event("vision_fallback", vision_fallback_used)

        # ===== 1ì°¨ AI: ì „ë¬¸ê°€ ë¶„ì„ (GPT-5, JSON Schema ê°•ì œ) =====
        logger.info(f"=== 1ì°¨ AI ë¶„ì„ ì‹œì‘ (GPT-5 + JSON Schema, ê°•ì•„ì§€: {dog_name}) ===")

        raw_json = None
        try:
            with tracker.span("expert_analysis"):
                # í”„ë¡¬í”„íŠ¸ ìƒì„±
                logger.debug("1ì°¨ AI í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
                expert_prompt = build_expert_analysis_prompt(
                    responses=responses,
                    dog_photo=dog_photo,
                    behavior_media=behavior_media,
                    vision_analysis=vision_analysis
                )

                # GPT-5 Responses API í˜¸ì¶œ (JSON Schema ê°•ì œ)
                logger.info("1ì°¨ AI GPT-5 API í˜¸ì¶œ ì‹œì‘ (JSON Schema ê°•ì œ)...")
                raw_response = await call_gpt5_api(
                    system=expert_prompt["system"],
                    user=expert_prompt["user"],
                    max_retries=3,
                    model=settings.AI_TEXT_MODEL,
                    use_json_schema=True,
                    json_schema=EXPERT_ANALYSIS_SCHEMA,
                    temperature=settings.AI_TEXT_TEMPERATURE_EXPERT,
                    verbosity="medium",  # ì¤‘ê°„ ìƒì„¸ë„
                    reasoning_effort="medium"  # ì¤‘ê°„ ì¶”ë¡  ê°•ë„
                )

                # JSON íŒŒì‹±
                logger.debug("1ì°¨ AI ì‘ë‹µ JSON íŒŒì‹± ì¤‘...")
                raw_json = parse_json_response(raw_response)

                # ===== Self-Healing: Schema ê²€ì¦ =====
                is_valid, error_msg = validate_expert_json(raw_json)

                if not is_valid:
                    logger.warning(f"Schema ê²€ì¦ ì‹¤íŒ¨: {error_msg}")
                    logger.info("=== Self-Healing ë‹¨ê³„ 1: Normalize ì‹œë„ ===")

                    # 1) Normalize (ìë™ ë³´ì •)
                    raw_json = normalize_expert_json(raw_json)
                    logger.info("Normalize ì™„ë£Œ")

                    # 2) ì¬ê²€ì¦
                    is_valid, error_msg = validate_expert_json(raw_json)

                    if not is_valid:
                        logger.warning(f"Normalize í›„ì—ë„ ê²€ì¦ ì‹¤íŒ¨: {error_msg}")
                        logger.info("=== Self-Healing ë‹¨ê³„ 2: ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ì‹œë„ ===")

                        # 3) ìˆ˜ì • í”„ë¡¬í”„íŠ¸
                        try:
                            raw_json = await fix_json_with_prompt(
                                broken_json=raw_json,
                                error_message=error_msg,
                                original_prompt=expert_prompt["user"]
                            )

                            # 4) ìµœì¢… ê²€ì¦
                            is_valid, error_msg = validate_expert_json(raw_json)

                            if not is_valid:
                                logger.error(f"ìˆ˜ì • í”„ë¡¬í”„íŠ¸ í›„ì—ë„ ê²€ì¦ ì‹¤íŒ¨: {error_msg}")
                                logger.warning("ìµœì¢… Normalize ì ìš©")
                                raw_json = normalize_expert_json(raw_json)

                        except Exception as fix_error:
                            logger.error(f"ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ì‹¤íŒ¨: {str(fix_error)}")
                            logger.warning("Normalizeë¡œ ë³µêµ¬")
                            raw_json = normalize_expert_json(raw_json)

            logger.info("1ì°¨ AI ë¶„ì„ ë° ê²€ì¦ ì™„ë£Œ!")

        except Exception as e:
            expert_mock_used = True
            # ìµœí›„ í´ë°±: Mock ë°ì´í„°
            logger.error("===== 1ì°¨ AI ì‹¤íŒ¨ - Mock ë°ì´í„° í´ë°± =====")
            logger.error(f"Error: {str(e)}", exc_info=True)

            problem_type = main_concerns[0] if main_concerns else "barking"
            mock_result = get_mock_result_by_problem(problem_type)

            raw_json = {
                "analysis_summary": {
                    "core_issue": "ë¶„ì„ ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸°ë³¸ ì‘ë‹µ",
                    "root_cause": "API ì˜¤ë¥˜",
                    "key_characteristics": ["ì •ë³´ ë¶€ì¡±", "ì„ì‹œ ì‘ë‹µ", "ì¬ì‹œë„ ê¶Œì¥"]
                },
                "solutions_best_fit": [
                    {"title": "ì†”ë£¨ì…˜ 1", "content": "ê¸°ë³¸ ì†”ë£¨ì…˜", "details": ["ì„ì‹œ ì‘ë‹µ"], "expected_outcome": "ê°œì„  ê¸°ëŒ€"},
                    {"title": "ì†”ë£¨ì…˜ 2", "content": "ê¸°ë³¸ ì†”ë£¨ì…˜", "details": ["ì„ì‹œ ì‘ë‹µ"], "expected_outcome": "ê°œì„  ê¸°ëŒ€"},
                    {"title": "ì†”ë£¨ì…˜ 3", "content": "ê¸°ë³¸ ì†”ë£¨ì…˜", "details": ["ì„ì‹œ ì‘ë‹µ"], "expected_outcome": "ê°œì„  ê¸°ëŒ€"}
                ],
                "future_guidance": [
                    {"principle": "ì›ì¹™ 1", "content": "ë‚´ìš©", "action": "í–‰ë™"},
                    {"principle": "ì›ì¹™ 2", "content": "ë‚´ìš©", "action": "í–‰ë™"},
                    {"principle": "ì›ì¹™ 3", "content": "ë‚´ìš©", "action": "í–‰ë™"}
                ],
                "core_message": "ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "confidence_score": 0.3
            }

        tracker.mark_event("expert_mock_fallback", expert_mock_used)

        # ===== 2ì°¨ AI: ë§ˆë¦¬ í˜ë¥´ì†Œë‚˜ ë³€í™˜ (GPT-5, ìì—°ì–´) =====
        logger.info(f"=== 2ì°¨ AI ë³€í™˜ ì‹œì‘ (GPT-5, ê°•ì•„ì§€: {dog_name}) ===")

        try:
            with tracker.span("mari_conversion"):
                mari_prompt = build_mari_conversion_prompt(
                    raw_json=raw_json,
                    dog_name=dog_name,
                    dog_age=dog_age,
                    hardest_part=hardest_part
                )

                # GPT-5 Responses API í˜¸ì¶œ (JSON Schema ëª¨ë“œ)
                logger.info("2ì°¨ AI GPT-5 API í˜¸ì¶œ ì‹œì‘ (JSON Schema)...")
                mari_json_str = await call_gpt5_api(
                    system=mari_prompt["system"],
                    user=mari_prompt["user"],
                    max_retries=2,
                    model=settings.AI_TEXT_MODEL,
                    use_json_schema=True,
                    json_schema=MARI_NARRATIVE_SCHEMA,
                    temperature=settings.AI_TEXT_TEMPERATURE_MARI,
                    verbosity="medium",
                    reasoning_effort="low"
                )
                mari_story = parse_json_response(mari_json_str)
                final_text = format_mari_story_markdown(mari_story)
                logger.info("2ì°¨ AI ë³€í™˜ ì„±ê³µ!")

        except Exception as e:
            mari_template_used = True
            logger.error("===== 2ì°¨ AI ì‹¤íŒ¨ - simple_template_conversion í´ë°± =====")
            logger.error(f"Error: {str(e)}", exc_info=True)
            final_text = simple_template_conversion(raw_json, dog_name, dog_age)
            mari_story = None

        tracker.mark_event("mari_template_fallback", mari_template_used)

        # ê²°ê³¼ ë°˜í™˜
        return {
            "final_text": final_text,
            "confidence_score": raw_json.get("confidence_score", 0.5),
            "raw_json": raw_json,
            "mari_story": mari_story
        }

    except Exception as unexpected:
        final_status = "error"
        tracker.set_status("error", str(unexpected))
        raise
    finally:
        tracker.add_metadata(
            used_mock_result=expert_mock_used,
            mari_template_fallback=mari_template_used,
            vision_fallback_used=vision_fallback_used,
        )
        tracker.finish(final_status)


# ===== í´ë°±: ê°„ë‹¨í•œ í…œí”Œë¦¿ ë³€í™˜ =====

def simple_template_conversion(raw_json: dict, dog_name: str, dog_age: str) -> str:
    """
    2ì°¨ AI ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê°„ë‹¨í•œ í…œí”Œë¦¿ ë³€í™˜.

    Args:
        raw_json: 1ì°¨ AI ê²°ê³¼
        dog_name: ê°•ì•„ì§€ ì´ë¦„
        dog_age: ê°•ì•„ì§€ ë‚˜ì´

    Returns:
        str: Markdown í…ìŠ¤íŠ¸
    """
    summary = raw_json.get("analysis_summary", {})
    solutions = raw_json.get("solutions_best_fit", [])
    guidance = raw_json.get("future_guidance", [])
    core_message = raw_json.get("core_message", "")

    text = f"""**"{dog_name}({dog_age})ì˜ í–‰ë™ ë¶„ì„ ê²°ê³¼ì˜ˆìš”!"**

{summary.get("core_issue", "ë¶„ì„ ê²°ê³¼")}

---

ğŸ¾ **ì´ëŸ° ì†”ë£¨ì…˜ì´ {dog_name}ì—ê²Œ ê°€ì¥ ì˜ ë§ì•„ìš”!**

"""

    # ì†”ë£¨ì…˜ 3ê°œ ì¶”ê°€
    for i, sol in enumerate(solutions[:3], 1):
        text += f"""**{i}. {sol.get("title", f"ì†”ë£¨ì…˜ {i}")}**

{sol.get("content", "ë‚´ìš© ì—†ìŒ")}

"""

    # ì½”ì–´ ë©”ì‹œì§€
    if core_message:
        text += f"""ğŸŒ± **ë§ˆë¦¬ì˜ í•œë§ˆë””:**

"{core_message}"

---

"""

    # ë¯¸ë˜ ê°€ì´ë˜ìŠ¤
    text += f"""ğŸ¾ **ì•ìœ¼ë¡œ ì´ë ‡ê²Œ í•´ë³´ì„¸ìš”!**

"""

    for g in guidance[:3]:
        text += f"- {g.get('principle', 'ì›ì¹™')}: {g.get('action', 'í–‰ë™')}\n"

    text += f"""

**{dog_name}ëŠ” ì˜í•˜ê³  ìˆì–´ìš”. ë³´í˜¸ìë‹˜ë„ ë„ˆë¬´ ì˜í•˜ê³  ê³„ì„¸ìš” ğŸ’›**
"""

    return text


def format_mari_story_markdown(mari_story: dict | None) -> str:
    if not mari_story:
        return ""

    header = mari_story.get("header", {})
    solutions = mari_story.get("solutions", [])
    guidance = mari_story.get("guidance", [])
    closing = mari_story.get("mari_closing", {})

    parts: list[str] = []
    title = header.get("title")
    if title:
        parts.append(f"**\"{title}\"**\n")
    summary = header.get("summary")
    if summary:
        parts.append(summary + "\n")

    if solutions:
        parts.append("\n---\n\nğŸ¾ **ì´ëŸ° ì†”ë£¨ì…˜ì´ ê°€ì¥ ì˜ ë§ì•„ìš”!**\n")
        for idx, sol in enumerate(solutions, start=1):
            steps = "\n".join(f"- {step}" for step in sol.get("steps", []))
            parts.append(
                f"{idx}ï¸âƒ£ **{sol.get('title', 'ì†”ë£¨ì…˜')}**\n"
                f"{sol.get('content', '')}\n{steps}\n"
                f"âœ¨ ê¸°ëŒ€ íš¨ê³¼: {sol.get('outcome', '')}\n\n"
            )

    if guidance:
        parts.append("---\n\nğŸ¾ **ì•ìœ¼ë¡œ ì´ë ‡ê²Œ í•´ë³´ì„¸ìš”!**\n")
        for item in guidance:
            parts.append(
                f"- **{item.get('principle', '')}**: {item.get('description', '')}\n"
                f"  â†’ {item.get('action', '')}\n"
            )

    core_message = closing.get("core_message")
    final_quote = closing.get("final_quote")
    if core_message or final_quote:
        parts.append("\n---\n\n")
    if core_message:
        parts.append(core_message + "\n\n")
    if final_quote:
        parts.append(final_quote)

    return "".join(parts).strip()
